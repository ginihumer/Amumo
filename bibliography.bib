@inproceedings{radford_learning_2021,
        title = {Learning Transferable Visual Models From Natural Language Supervision},
        url = {https://proceedings.mlr.press/v139/radford21a.html},
        language = {en},
        urldate = {2022-12-30},
        booktitle = {Proceedings of the 38th International Conference on Machine Learning},
        publisher = {PMLR},
        author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
        month = jul,
        year = {2021},
        note = {ISSN: 2640-3498},
        pages = {8748--8763},
    }

    @article{liang_mind_2022,
        title = {Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning},
        shorttitle = {Mind the Gap},
        url = {http://arxiv.org/abs/2203.02053},
        urldate = {2023-05-15},
        journal={arXivreprint},
        author = {Liang, Weixin and Zhang, Yuhui and Kwon, Yongchan and Yeung, Serena and Zou, James},
        month = oct,
        year = {2022},
    }

    @inproceedings{goel_cyclip_2022,
        title = {CyCLIP: Cyclic Contrastive Language-Image Pretraining},
        volume = {35},
        url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/2cd36d327f33d47b372d4711edd08de0-Paper-Conference.pdf},
        booktitle = {Advances in Neural Information Processing Systems},
        publisher = {Curran Associates, Inc.},
        author = {Goel, Shashank and Bansal, Hritik and Bhatia, Sumit and Rossi, Ryan and Vinay, Vishwa and Grover, Aditya},
        editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
        year = {2022},
        pages = {6704--6719},
    }

    @inproceedings{furst_cloob_2022,
        title = {CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP},
        volume = {35},
        url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/8078e76f913e31b8467e85b4c0f0d22b-Paper-Conference.pdf},
        booktitle = {Advances in Neural Information Processing Systems},
        publisher = {Curran Associates, Inc.},
        author = {Fürst, Andreas and Rumetshofer, Elisabeth and Lehner, Johannes and Tran, Viet T. and Tang, Fei and Ramsauer, Hubert and Kreil, David and Kopp, Michael and Klambauer, Günter and Bitto, Angela and Hochreiter, Sepp},
        editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
        year = {2022},
        pages = {20450--20468},
    }
    
    @inproceedings{rombach_high-resolution_2022,
        address = {New Orleans, LA, USA},
        title = {High-Resolution Image Synthesis with Latent Diffusion Models},
        isbn = {978-1-66546-946-3},
        url = {https://ieeexplore.ieee.org/document/9878449/},
        doi = {10.1109/CVPR52688.2022.01042},
        language = {en},
        urldate = {2023-04-11},
        booktitle = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        publisher = {IEEE},
        author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bjorn},
        month = jun,
        year = {2022},
        pages = {10674--10685},
    }


    @article{wang_diffusiondb_2022,
        title = {DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models},
        shorttitle = {DiffusionDB},
        journal={arXivreprint},
        url = {http://arxiv.org/abs/2210.14896},
        abstract = {With recent advancements in diffusion models, users can generate high-quality images by writing text prompts in natural language. However, generating images with desired details requires proper prompts, and it is often unclear how a model reacts to different prompts and what the best prompts are. To help researchers tackle these critical challenges, we introduce DiffusionDB, the first large-scale text-to-image prompt dataset. DiffusionDB contains 14 million images generated by Stable Diffusion using prompts and hyperparameters specified by real users. We analyze prompts in the dataset and discuss key properties of these prompts. The unprecedented scale and diversity of this human-actuated dataset provide exciting research opportunities in understanding the interplay between prompts and generative models, detecting deepfakes, and designing human-AI interaction tools to help users more easily use these models. DiffusionDB is publicly available at: https://poloclub.github.io/diffusiondb.},
        urldate = {2023-04-11},
        publisher = {arXiv},
        author = {Wang, Zijie J. and Montoya, Evan and Munechika, David and Yang, Haoyang and Hoover, Benjamin and Chau, Duen Horng},
        month = nov,
        year = {2022},
    }


    @article{girdhar_imagebind_2023,
        title = {ImageBind: One Embedding Space To Bind Them All},
        shorttitle = {ImageBind},
        url = {http://arxiv.org/abs/2305.05665},
        abstract = {We present ImageBind, an approach to learn a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. We show that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient to bind the modalities together. ImageBind can leverage recent large scale vision-language models, and extends their zero-shot capabilities to new modalities just by using their natural pairing with images. It enables novel emergent applications 'out-of-the-box' including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation. The emergent capabilities improve with the strength of the image encoder and we set a new state-of-the-art on emergent zero-shot recognition tasks across modalities, outperforming specialist supervised models. Finally, we show strong few-shot recognition results outperforming prior work, and that ImageBind serves as a new way to evaluate vision models for visual and non-visual tasks.},
        urldate = {2023-05-10},
        publisher = {arXiv},
        author = {Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
        month = may,
        year = {2023},
        journal={arXivreprint},
    }


    @article{lin_microsoft_2015,
        title = {Microsoft COCO: Common Objects in Context},
        shorttitle = {Microsoft COCO},
        url = {http://arxiv.org/abs/1405.0312},
        urldate = {2023-06-27},
        publisher = {arXiv},
        author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
        month = feb,
        year = {2015},
        keywords = {Computer Science - Computer Vision and Pattern Recognition},
        journal={arXivreprint},
    }

    @misc{crowson_cloob-training_2023,
        title = {cloob-training},
        copyright = {MIT},
        url = {https://github.com/crowsonkb/cloob-training},
        abstract = {CLOOB training (JAX) and inference (JAX and PyTorch)},
        urldate = {2023-06-27},
        author = {Crowson, Katherine},
        month = may,
        year = {2023},
        note = {original-date: 2022-03-24T22:33:36Z},
    }
    

    @inproceedings{timme_robustness_2020,
        address = {Budapest, Hungary},
        title = {On the Robustness of Convolutional Neural Networks Regarding Transformed Input Images},
        isbn = {978-989-758-475-6},
        shorttitle = {On the {Robustness} of {Convolutional} {Neural} {Networks} {Regarding} {Transformed} {Input} {Images}},
        url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010107203960403},
        doi = {10.5220/0010107203960403},
        language = {en},
        urldate = {2023-06-30},
        booktitle = {Proceedings of the 12th {International} {Joint} {Conference} on {Computational} {Intelligence}},
        publisher = {SCITEPRESS - Science and Technology Publications},
        author = {Timme, Frederik and Kerdels, Jochen and Peters, Gabriele},
        year = {2020},
        pages = {396--403},
    }


    @article{eckelt_visual_2022,
        title = {Visual Exploration of Relationships and Structure in Low-Dimensional Embeddings},
        issn = {1941-0506},
        doi = {10.1109/TVCG.2022.3156760},
        journal = {IEEE Transactions on Visualization and Computer Graphics},
        author = {Eckelt, Klaus and Hinterreiter, Andreas and Adelberger, Patrick and Walchshofer, Conny and Dhanoa, Vaishali and Humer, Christina and Heckmann, Moritz and Steinparz, Christian and Streit, Marc},
        year = {2022},
        note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
        keywords = {Visualization, Task analysis, aggregation, comparison, Data visualization, Dimensionality reduction, Layout, layout enrichment, projection, Space exploration, Trajectory, visual analytics, Visual analytics},
        pages = {1--1},
    }