{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christina\\AppData\\Roaming\\Python\\Python39\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\Christina\\AppData\\Roaming\\Python\\Python39\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\Christina\\AppData\\Roaming\\Python\\Python39\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\Christina\\AppData\\Roaming\\Python\\Python39\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "from amumo import model as am_model\n",
    "from amumo import data as am_data\n",
    "from amumo import widgets as am_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MSCOCO-Val_size-100'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Helpers\n",
    "def get_data_helper(dataset, filters=[], method=any):\n",
    "    all_images, all_prompts = dataset.get_filtered_data(filters, method=method)\n",
    "    print(len(all_images))\n",
    "\n",
    "    dataset_name = dataset.name\n",
    "    if len(filters) > 0:\n",
    "        dataset_name = dataset_name + '_filter-' + method.__name__ + '_' + '-'.join(filters)\n",
    "    else:\n",
    "        dataset_name = dataset_name + '_size-%i'%len(all_images)\n",
    "\n",
    "    return all_images, all_prompts, dataset_name\n",
    "\n",
    "# # load dataset\n",
    "# dataset = am_data.DiffusionDB_Dataset(path=\"2m_first_1k\", batch_size=100) # data helper for the diffusionDB dataset; for the interactive prototype, we only use a random subset of 100 samples\n",
    "# all_images, all_prompts = dataset.get_data()\n",
    "# cache_name = 'diffusiondb_random_100' # path used to cache the results\n",
    "\n",
    "# Load Data\n",
    "data_path = '../../../../../Data/'\n",
    "# subset of mscoco validation data\n",
    "dataset_mscoco_val = am_data.MSCOCO_Val_Dataset(path=data_path+'mscoco/validation', batch_size=100) \n",
    "mscoco_val_images, mscoco_val_prompts, mscoco_val_dataset_name = get_data_helper(dataset_mscoco_val, filters=[], method=any)\n",
    "mscoco_val_dataset_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from amumo.CLOOB_local.clip import clip as cloob\n",
    "from amumo.CLOOB_local.clip.model import CLIPGeneral\n",
    "from amumo.CLOOB_local.cloob_training import model_pt, pretrained\n",
    "\n",
    "class Custom_CLOOB_Model(am_model.CLIPModelInterface):\n",
    "    available_models = ['clip_infoLOOB', 'clip', 'cloob_infoNCE', 'cloob']\n",
    "    model_name = ''\n",
    "\n",
    "    def __init__(self, name='clip_infoLOOB', device='cpu') -> None:\n",
    "        super().__init__(name, device)\n",
    "\n",
    "        self.model_name += name\n",
    "\n",
    "        ckpt_name = name + '_rn50_cc_epoch_31.pt' # cloob_infoNCE_rn50_cc_epoch_31.pt\n",
    "        checkpoint_path = 'checkpoints/cloob_tests/' + ckpt_name\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model_config_file = os.path.join('../amumo/CLOOB_local/training/model_configs/', checkpoint['model_config_file'])\n",
    "\n",
    "        print('Loading model from', model_config_file)\n",
    "        assert os.path.exists(model_config_file), 'config file does not exist'\n",
    "        with open(model_config_file, 'r') as f:\n",
    "            model_info = json.load(f)\n",
    "        self.model = CLIPGeneral(**model_info)\n",
    "        self.model.eval()\n",
    "\n",
    "        sd = checkpoint[\"state_dict\"]\n",
    "        sd = {k[len('module.'):]: v for k, v in sd.items()}\n",
    "        if 'logit_scale_hopfield' in sd:\n",
    "            sd.pop('logit_scale_hopfield', None)\n",
    "        self.model.load_state_dict(sd)\n",
    "\n",
    "        self.preprocess = cloob._transform(self.model.visual.input_resolution, is_train=False)\n",
    "\n",
    "        self.logit_scale = self.model.logit_inv_tau\n",
    "\n",
    "\n",
    "    def encode_image(self, images):\n",
    "        images = [self.preprocess(i) for i in images]\n",
    "        image_input = torch.tensor(np.stack(images)).to(self.device)\n",
    "        return self.model.encode_image(image_input).float().cpu()\n",
    "\n",
    "    def encode_text(self, texts):\n",
    "        text_tokens = cloob.tokenize(texts).to(self.device)\n",
    "        return self.model.encode_text(text_tokens).float().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_clip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90b44cd5c7c42e8b8f4bc56f1dfb708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLIPExplorerWidget(children=(VBox(children=(HBox(children=(Dropdown(description='Model: ', options=('clip', 'câ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found cached embeddings for MSCOCO-Val_size-100_clip_infoLOOB_clip_infoLOOB\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_cloob\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_infoNCE_cloob_infoNCE\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_clip\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_infoLOOB_clip_infoLOOB\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_infoNCE_cloob_infoNCE\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_cloob\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_clip\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_infoLOOB_clip_infoLOOB\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_infoNCE_cloob_infoNCE\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_cloob\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_infoNCE_cloob_infoNCE\n",
      " True\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_cloob\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_infoLOOB_clip_infoLOOB\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_clip\n"
     ]
    }
   ],
   "source": [
    "am_widgets.CLIPExplorerWidget(mscoco_val_dataset_name, mscoco_val_images, mscoco_val_prompts, models=[Custom_CLOOB_Model(name='clip'), Custom_CLOOB_Model(name='clip_infoLOOB'), Custom_CLOOB_Model(name='cloob'), Custom_CLOOB_Model(name='cloob_infoNCE')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "Loading model from ../amumo/CLOOB_local/training/model_configs/RN50.json\n",
      "True [False, False, False, False] {'clip': <__main__.Custom_CLOOB_Model object at 0x0000024C28D55F40>, 'clip_infoLOOB': <__main__.Custom_CLOOB_Model object at 0x0000024C324A1F70>, 'cloob': <__main__.Custom_CLOOB_Model object at 0x0000024C32E1AF70>, 'cloob_infoNCE': <__main__.Custom_CLOOB_Model object at 0x0000024C324C8F70>}\n",
      "found cached embeddings for MSCOCO-Val_size-100_clip_clip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christina\\repositories\\icg\\researchstay\\amumo\\amumo\\widgets.py:844: FutureWarning:\n",
      "\n",
      "The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "\n",
      "c:\\users\\christina\\repositories\\icg\\researchstay\\amumo\\amumo\\widgets.py:844: VisibleDeprecationWarning:\n",
      "\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found cached embeddings for MSCOCO-Val_size-100_clip_infoLOOB_clip_infoLOOB\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_cloob\n",
      "found cached embeddings for MSCOCO-Val_size-100_cloob_infoNCE_cloob_infoNCE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469257978df842ee9bc0ede4e7963029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLIPComparerWidget(children=(HoverWidget(children=(VBox(children=(HTML(value='', layout=Layout(width='300px'))â€¦"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['clip_infoLOOB', 'clip', 'cloob_infoNCE', 'cloob']\n",
    "am_widgets.CLIPComparerWidget(mscoco_val_dataset_name, mscoco_val_images, mscoco_val_prompts, models=[Custom_CLOOB_Model(name='clip'), Custom_CLOOB_Model(name='clip_infoLOOB'), Custom_CLOOB_Model(name='cloob'), Custom_CLOOB_Model(name='cloob_infoNCE')], zmin=-0.4, zmax=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amumo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
