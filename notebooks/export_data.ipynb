{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ginihumer/CLIP-explorer.git\n",
      "  Cloning https://github.com/ginihumer/CLIP-explorer.git to c:\\users\\christina\\appdata\\local\\temp\\pip-req-build-ou6tjn_p\n",
      "  Resolved https://github.com/ginihumer/CLIP-explorer.git to commit aeec3903c1d4a4510cecee032ac559aa8039bce1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting clip@ git+https://github.com/openai/CLIP.git@a9b1bf5920416aaeaec965c25dd9e8f98c864f16 (from CLIP-explorer==0.1.32)\n",
      "  Using cached clip-1.0-py3-none-any.whl\n",
      "Collecting open-clip-torch==2.20.0 (from CLIP-explorer==0.1.32)\n",
      "  Using cached open_clip_torch-2.20.0-py3-none-any.whl (1.5 MB)\n",
      "Collecting datasets==2.12.0 (from CLIP-explorer==0.1.32)\n",
      "  Using cached datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "Collecting webdataset==0.2.48 (from CLIP-explorer==0.1.32)\n",
      "  Using cached webdataset-0.2.48-py3-none-any.whl (51 kB)\n",
      "Collecting plotly (from CLIP-explorer==0.1.32)\n",
      "  Downloading plotly-5.15.0-py2.py3-none-any.whl (15.5 MB)\n",
      "     --------------------------------------- 15.5/15.5 MB 22.6 MB/s eta 0:00:00\n",
      "Collecting ipywidgets==8.0.6 (from CLIP-explorer==0.1.32)\n",
      "  Using cached ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "Collecting ipykernel==6.23.1 (from CLIP-explorer==0.1.32)\n",
      "  Using cached ipykernel-6.23.1-py3-none-any.whl (152 kB)\n",
      "Collecting scikit-learn (from CLIP-explorer==0.1.32)\n",
      "  Downloading scikit_learn-1.3.0-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "     ---------------------------------------- 9.3/9.3 MB 27.1 MB/s eta 0:00:00\n",
      "Collecting openTSNE (from CLIP-explorer==0.1.32)\n",
      "  Downloading openTSNE-1.0.0-cp39-cp39-win_amd64.whl (390 kB)\n",
      "     ------------------------------------- 390.4/390.4 kB 25.3 MB/s eta 0:00:00\n",
      "Collecting umap-learn (from CLIP-explorer==0.1.32)\n",
      "  Using cached umap_learn-0.5.3-py3-none-any.whl\n",
      "Collecting numpy==1.23.5 (from CLIP-explorer==0.1.32)\n",
      "  Using cached numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Collecting pycocotools (from CLIP-explorer==0.1.32)\n",
      "  Using cached pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: transformers in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from CLIP-explorer==0.1.32) (4.30.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (1.4.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (0.15.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (23.0)\n",
      "Collecting responses<0.19 (from datasets==2.12.0->CLIP-explorer==0.1.32)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from datasets==2.12.0->CLIP-explorer==0.1.32) (6.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.1.2)\n",
      "Collecting debugpy>=1.6.5 (from ipykernel==6.23.1->CLIP-explorer==0.1.32)\n",
      "  Using cached debugpy-1.6.7-cp39-cp39-win_amd64.whl (4.8 MB)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (8.4.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (8.1.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (1.5.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (6.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipykernel==6.23.1->CLIP-explorer==0.1.32) (5.7.1)\n",
      "Collecting widgetsnbextension~=4.0.7 (from ipywidgets==8.0.6->CLIP-explorer==0.1.32)\n",
      "  Using cached widgetsnbextension-4.0.8-py3-none-any.whl (2.3 MB)\n",
      "Collecting jupyterlab-widgets~=3.0.7 (from ipywidgets==8.0.6->CLIP-explorer==0.1.32)\n",
      "  Using cached jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (2.0.1)\n",
      "Collecting torchvision (from open-clip-torch==2.20.0->CLIP-explorer==0.1.32)\n",
      "  Using cached torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: regex in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (2023.6.3)\n",
      "Collecting ftfy (from open-clip-torch==2.20.0->CLIP-explorer==0.1.32)\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting sentencepiece (from open-clip-torch==2.20.0->CLIP-explorer==0.1.32)\n",
      "  Using cached sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
      "Requirement already satisfied: protobuf<4 in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (3.19.4)\n",
      "Collecting timm (from open-clip-torch==2.20.0->CLIP-explorer==0.1.32)\n",
      "  Using cached timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "Collecting braceexpand (from webdataset==0.2.48->CLIP-explorer==0.1.32)\n",
      "  Using cached braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Collecting scipy (from openTSNE->CLIP-explorer==0.1.32)\n",
      "  Downloading scipy-1.11.1-cp39-cp39-win_amd64.whl (44.1 MB)\n",
      "     --------------------------------------- 44.1/44.1 MB 16.4 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1 (from scikit-learn->CLIP-explorer==0.1.32)\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "     ------------------------------------- 302.0/302.0 kB 19.4 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->CLIP-explorer==0.1.32)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly->CLIP-explorer==0.1.32)\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from pycocotools->CLIP-explorer==0.1.32) (3.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from transformers->CLIP-explorer==0.1.32) (3.12.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from transformers->CLIP-explorer==0.1.32) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from transformers->CLIP-explorer==0.1.32) (0.3.1)\n",
      "Collecting numba>=0.49 (from umap-learn->CLIP-explorer==0.1.32)\n",
      "  Downloading numba-0.57.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 26.9 MB/s eta 0:00:00\n",
      "Collecting pynndescent>=0.5 (from umap-learn->CLIP-explorer==0.1.32)\n",
      "  Using cached pynndescent-0.5.10-py3-none-any.whl\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from aiohttp->datasets==2.12.0->CLIP-explorer==0.1.32) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from aiohttp->datasets==2.12.0->CLIP-explorer==0.1.32) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from aiohttp->datasets==2.12.0->CLIP-explorer==0.1.32) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from aiohttp->datasets==2.12.0->CLIP-explorer==0.1.32) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from aiohttp->datasets==2.12.0->CLIP-explorer==0.1.32) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from aiohttp->datasets==2.12.0->CLIP-explorer==0.1.32) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from aiohttp->datasets==2.12.0->CLIP-explorer==0.1.32) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.12.0->CLIP-explorer==0.1.32) (4.6.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (2.15.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (67.8.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-client>=6.1.12->ipykernel==6.23.1->CLIP-explorer==0.1.32) (4.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel==6.23.1->CLIP-explorer==0.1.32) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.23.1->CLIP-explorer==0.1.32) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.23.1->CLIP-explorer==0.1.32) (305.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools->CLIP-explorer==0.1.32) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools->CLIP-explorer==0.1.32) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools->CLIP-explorer==0.1.32) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools->CLIP-explorer==0.1.32) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools->CLIP-explorer==0.1.32) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools->CLIP-explorer==0.1.32) (3.1.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools->CLIP-explorer==0.1.32) (5.12.0)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba>=0.49->umap-learn->CLIP-explorer==0.1.32)\n",
      "  Downloading llvmlite-0.40.1-cp39-cp39-win_amd64.whl (27.7 MB)\n",
      "     --------------------------------------- 27.7/27.7 MB 22.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from requests>=2.19.0->datasets==2.12.0->CLIP-explorer==0.1.32) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from requests>=2.19.0->datasets==2.12.0->CLIP-explorer==0.1.32) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from requests>=2.19.0->datasets==2.12.0->CLIP-explorer==0.1.32) (2023.5.7)\n",
      "Requirement already satisfied: sympy in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from torch>=1.9.0->open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from torch>=1.9.0->open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.9.0->open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (3.1.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from ftfy->open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (0.2.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from pandas->datasets==2.12.0->CLIP-explorer==0.1.32) (2022.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel==6.23.1->CLIP-explorer==0.1.32) (3.11.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.8.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel==6.23.1->CLIP-explorer==0.1.32) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from jinja2->torch>=1.9.0->open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (2.1.1)\n",
      "Requirement already satisfied: executing in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\christina\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.23.1->CLIP-explorer==0.1.32) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\christina\\anaconda3\\envs\\ibm-experiments\\lib\\site-packages (from sympy->torch>=1.9.0->open-clip-torch==2.20.0->CLIP-explorer==0.1.32) (1.3.0)\n",
      "Building wheels for collected packages: CLIP-explorer, pycocotools\n",
      "  Building wheel for CLIP-explorer (setup.py): started\n",
      "  Building wheel for CLIP-explorer (setup.py): finished with status 'done'\n",
      "  Created wheel for CLIP-explorer: filename=CLIP_explorer-0.1.32-py3-none-any.whl size=1430722 sha256=36ca7f2b53e6840eb7cd396e201427946eb35269ae1d6bd5986a63892c9dcf69\n",
      "  Stored in directory: C:\\Users\\Christina\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-27b6rpvl\\wheels\\09\\fc\\8b\\3b8a1f10143be547929a0768142222f15b2860f13226a18139\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp39-cp39-win_amd64.whl size=80883 sha256=e0f0999d1c2c1dfa2c9058b8e5168a355ecb9c474584f06141ae9b4c6e53473d\n",
      "  Stored in directory: c:\\users\\christina\\appdata\\local\\pip\\cache\\wheels\\2f\\58\\25\\e78f1f766e904a9071266661d20d0bc6644df86bcd160aba11\n",
      "Successfully built CLIP-explorer pycocotools\n",
      "Installing collected packages: sentencepiece, braceexpand, widgetsnbextension, threadpoolctl, tenacity, numpy, llvmlite, jupyterlab-widgets, joblib, ftfy, debugpy, webdataset, scipy, responses, plotly, numba, torchvision, scikit-learn, timm, pynndescent, pycocotools, openTSNE, ipykernel, datasets, clip, umap-learn, open-clip-torch, ipywidgets, CLIP-explorer\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.0\n",
      "    Uninstalling numpy-1.25.0:\n",
      "      Successfully uninstalled numpy-1.25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/ginihumer/CLIP-explorer.git 'C:\\Users\\Christina\\AppData\\Local\\Temp\\pip-req-build-ou6tjn_p'\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Zugriff verweigert: 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\ibm-experiments\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas64__v0.3.23-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/ginihumer/CLIP-explorer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clipexplorer\n",
    "from clipexplorer import data as ce_data\n",
    "from clipexplorer import utils as ce_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Helpers\n",
    "def get_data_helper(dataset, filters=[], method=any):\n",
    "    all_images, all_prompts = dataset.get_filtered_data(filters, method=method)\n",
    "    print(len(all_images))\n",
    "\n",
    "    dataset_name = dataset.name\n",
    "    if len(filters) > 0:\n",
    "        dataset_name = dataset_name + '_filter-' + method.__name__ + '_' + '-'.join(filters)\n",
    "    else:\n",
    "        dataset_name = dataset_name + '_size-%i'%len(all_images)\n",
    "\n",
    "    return all_images, all_prompts, dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_dir_if_not_exists(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    return dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_directory = './exported_data_checkpoints/'\n",
    "create_dir_if_not_exists(export_directory)\n",
    "\n",
    "def export_data(dataset_name, images, prompts):\n",
    "\n",
    "    # create folder structure\n",
    "    dataset_directory = create_dir_if_not_exists(export_directory + dataset_name)\n",
    "    images_dir = create_dir_if_not_exists(dataset_directory + '/images')\n",
    "    similarities_dir = create_dir_if_not_exists(dataset_directory + '/similarities')\n",
    "\n",
    "    # save images\n",
    "    for i in range(len(images)):\n",
    "        im = images[i]\n",
    "        im.resize((400,400))\n",
    "        im.save('%s/%i.jpg'%(images_dir,i))\n",
    "\n",
    "    # save texts\n",
    "    with open(dataset_directory + \"/prompts.txt\", \"w\") as file:\n",
    "        for prompt in prompts:\n",
    "            file.write(prompt + \"\\n\")\n",
    "\n",
    "    # export projections and similarities\n",
    "    import torch\n",
    "    from sklearn.decomposition import PCA\n",
    "    from openTSNE import TSNE\n",
    "    from umap import UMAP\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    projections_df = pd.DataFrame({'emb_id': list(np.arange(0,len(images),1))+list(np.arange(0,len(prompts),1)), 'data_type':['image']*len(images)+['text']*len(prompts)})\n",
    "\n",
    "\n",
    "    for model in ['CLIP', 'CyCLIP', 'CLOOB', 'CLOOB_LAION400M']:\n",
    "        # compute embeddings\n",
    "        image_embedding_gap, text_embedding_gap, logit_scale = ce_utils.get_embedding(model, dataset_name, images, prompts)\n",
    "        image_embedding_nogap, text_embedding_nogap = ce_utils.get_closed_modality_gap(image_embedding_gap, text_embedding_gap)\n",
    "        \n",
    "        for image_embedding, text_embedding, mode in [(image_embedding_gap, text_embedding_gap, ''), (image_embedding_nogap, text_embedding_nogap, '_nogap')]:\n",
    "            \n",
    "            # compute similarities\n",
    "            similarity_image_text, similarity = ce_utils.get_similarity(image_embedding, text_embedding)\n",
    "            np.savetxt('%s/%s%s.csv'%(similarities_dir,model,mode), similarity, delimiter=',')\n",
    "            \n",
    "            # compute meta information and similarity clustering\n",
    "            meta_info = {}\n",
    "            meta_info['gap_distance'] = float(ce_utils.get_modality_distance(image_embedding, text_embedding))\n",
    "            meta_info['loss'] = float(ce_utils.calculate_val_loss(image_embedding, text_embedding, logit_scale.exp()))\n",
    "\n",
    "            idcs, clusters, clusters_unsorted = ce_utils.get_cluster_sorting(similarity_image_text)\n",
    "            cluster_labels = []\n",
    "            cluster_sizes = []\n",
    "            for c in set(clusters):\n",
    "                cluster_size = int(np.count_nonzero(clusters==c))\n",
    "                cluster_label = ce_utils.get_textual_label_for_cluster(np.where(clusters_unsorted==c)[0], prompts)\n",
    "                cluster_labels.append(cluster_label)\n",
    "                cluster_sizes.append(cluster_size)\n",
    "\n",
    "            idcs_reverse = np.argsort(idcs)\n",
    "            meta_info['cluster_sort_idcs'] = idcs.tolist()\n",
    "            meta_info['cluster_sort_idcs_reverse'] = idcs_reverse.tolist()\n",
    "            meta_info['cluster_sizes'] = cluster_sizes\n",
    "            meta_info['cluster_labels'] = cluster_labels\n",
    "            # print(meta_info)\n",
    "\n",
    "            with open(\"%s/%s%s_meta_info.json\"%(similarities_dir, model, mode), \"w\") as file:\n",
    "                json.dump(meta_info, file)\n",
    "\n",
    "            # compute projections\n",
    "            embedding = np.array(torch.concatenate([image_embedding, text_embedding]))\n",
    "\n",
    "            projection_methods = {\n",
    "                'PCA': PCA,\n",
    "                'UMAP': UMAP,\n",
    "                'TSNE': TSNE\n",
    "            }\n",
    "            for method in projection_methods.keys():\n",
    "                if method == 'PCA':\n",
    "                    proj = projection_methods[method](n_components=2)\n",
    "                else:\n",
    "                    proj = projection_methods[method](n_components=2, metric='cosine', random_state=31415)\n",
    "                \n",
    "                if method == 'TSNE':\n",
    "                    low_dim_data = proj.fit(embedding)\n",
    "                else:\n",
    "                    low_dim_data = proj.fit_transform(embedding)\n",
    "                \n",
    "                projections_df['%s%s_%s_x'%(model, mode, method)] = low_dim_data[:,0]\n",
    "                projections_df['%s%s_%s_y'%(model, mode, method)] = low_dim_data[:,1]\n",
    "\n",
    "\n",
    "    projections_df.to_csv(dataset_directory + '/projections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset diffusiondb (C:/Users/Christina/.cache/huggingface/datasets/poloclub___diffusiondb/2m_first_1k/0.9.1/b3bc1e64570dc7149af62c4bac49ecfbce16b683dd4fee083292fae1afa95f7c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427d5e6cd2a74a4e9299af89fc5a66b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Christina\\Repositories\\ICG\\Research Stay\\CLIP-explorer\\notebooks\\export_data.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# # subset of mscoco val dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# dataset_mscoco_val = ce_data.MSCOCO_Val_Dataset(path='/Users/christina/Data/mscoco/validation/', batch_size=100) # TODO: update to a relative path\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# mscoco_val_images, mscoco_val_prompts, mscoco_val_dataset_name = get_data_helper(dataset_mscoco_val, filters=[], method=any)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# export_data(mscoco_val_dataset_name, mscoco_val_images, mscoco_val_prompts)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# subset of diffusionDB data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dataset_diffusiondb \u001b[39m=\u001b[39m ce_data\u001b[39m.\u001b[39mDiffusionDB_Dataset(path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2m_first_1k\u001b[39m\u001b[39m\"\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m diffusiondb_images, diffusiondb_prompts, diffusiondb_dataset_name \u001b[39m=\u001b[39m get_data_helper(dataset_diffusiondb)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# export_data(diffusiondb_dataset_name, diffusiondb_images, diffusiondb_prompts)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# # Analyse filtered subset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# dataset_mscoco_val = ce_data.MSCOCO_Val_Dataset(path='/Users/christina/Data/mscoco/validation/', batch_size=100) # TODO: update to a relative path\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# mscoco_val_images_dogs, mscoco_val_prompts_dogs, mscoco_val_dataset_dogs_name = get_data_helper(dataset_mscoco_val, filters=['dog'], method=any) \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# export_data(mscoco_val_dataset_dogs_name, mscoco_val_images_dogs, mscoco_val_prompts_dogs)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m example_image_dir \u001b[39m=\u001b[39m create_dir_if_not_exists(export_directory \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexample_images/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Christina\\Repositories\\ICG\\Research Stay\\CLIP-explorer\\notebooks\\export_data.ipynb Cell 7\u001b[0m in \u001b[0;36mget_data_helper\u001b[1;34m(dataset, filters, method)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data_helper\u001b[39m(dataset, filters\u001b[39m=\u001b[39m[], method\u001b[39m=\u001b[39m\u001b[39many\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     all_images, all_prompts \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mget_filtered_data(filters, method\u001b[39m=\u001b[39;49mmethod)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(all_images))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Christina/Repositories/ICG/Research%20Stay/CLIP-explorer/notebooks/export_data.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     dataset_name \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\users\\christina\\repositories\\icg\\research stay\\clip-explorer\\clipexplorer\\data.py:50\u001b[0m, in \u001b[0;36mDatasetInterface.get_filtered_data\u001b[1;34m(self, filter_list, method)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_filtered_data\u001b[39m(\u001b[39mself\u001b[39m, filter_list, method\u001b[39m=\u001b[39m\u001b[39many\u001b[39m):\n\u001b[0;32m     47\u001b[0m     \u001b[39m# filter_list: a list of strings that are used for filtering\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[39m# method: any -> any substring given in filter_list is present; all -> all substrings must be contained in the string\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m filter_list \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(filter_list) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_data()\n\u001b[0;32m     52\u001b[0m     subset_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_prompts)) \u001b[39mif\u001b[39;00m method(substring \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_prompts[i]\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m substring \u001b[39min\u001b[39;00m filter_list)])\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(subset_ids) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\christina\\repositories\\icg\\research stay\\clip-explorer\\clipexplorer\\data.py:35\u001b[0m, in \u001b[0;36mDatasetInterface.get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m# create a random batch\u001b[39;00m\n\u001b[0;32m     33\u001b[0m batch_idcs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_random_subsample(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_images))\n\u001b[1;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_images[batch_idcs], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_prompts[batch_idcs]\n",
      "File \u001b[1;32mc:\\users\\christina\\repositories\\icg\\research stay\\clip-explorer\\clipexplorer\\data.py:408\u001b[0m, in \u001b[0;36mCustomDiffusionDBMapper.__getitem__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, indices):\n\u001b[1;32m--> 408\u001b[0m     subset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[indices]\n\u001b[0;32m    409\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselector \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselector \u001b[39min\u001b[39;00m subset:\n\u001b[0;32m    410\u001b[0m         \u001b[39mreturn\u001b[39;00m subset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselector]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\arrow_dataset.py:2778\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2777\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2778\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\arrow_dataset.py:2763\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2761\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2762\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2763\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[0;32m   2764\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[0;32m   2765\u001b[0m )\n\u001b[0;32m   2766\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\formatting\\formatting.py:624\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    622\u001b[0m python_formatter \u001b[39m=\u001b[39m PythonFormatter(features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m format_columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m     \u001b[39mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[0;32m    625\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    626\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\formatting\\formatting.py:400\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_column(pa_table)\n\u001b[0;32m    399\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_batch(pa_table)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\formatting\\formatting.py:444\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[39mself\u001b[39m)\n\u001b[0;32m    443\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_arrow_extractor()\u001b[39m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m--> 444\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpython_features_decoder\u001b[39m.\u001b[39;49mdecode_batch(batch)\n\u001b[0;32m    445\u001b[0m \u001b[39mreturn\u001b[39;00m batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\formatting\\formatting.py:221\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_batch\u001b[39m(\u001b[39mself\u001b[39m, batch: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mdecode_batch(batch) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39melse\u001b[39;00m batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\features\\features.py:1918\u001b[0m, in \u001b[0;36mFeatures.decode_batch\u001b[1;34m(self, batch, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1915\u001b[0m decoded_batch \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1916\u001b[0m \u001b[39mfor\u001b[39;00m column_name, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   1917\u001b[0m     decoded_batch[column_name] \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1918\u001b[0m         [\n\u001b[0;32m   1919\u001b[0m             decode_nested_example(\u001b[39mself\u001b[39m[column_name], value, token_per_repo_id\u001b[39m=\u001b[39mtoken_per_repo_id)\n\u001b[0;32m   1920\u001b[0m             \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m             \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m column\n\u001b[0;32m   1923\u001b[0m         ]\n\u001b[0;32m   1924\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   1925\u001b[0m         \u001b[39melse\u001b[39;00m column\n\u001b[0;32m   1926\u001b[0m     )\n\u001b[0;32m   1927\u001b[0m \u001b[39mreturn\u001b[39;00m decoded_batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\features\\features.py:1919\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1915\u001b[0m decoded_batch \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1916\u001b[0m \u001b[39mfor\u001b[39;00m column_name, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   1917\u001b[0m     decoded_batch[column_name] \u001b[39m=\u001b[39m (\n\u001b[0;32m   1918\u001b[0m         [\n\u001b[1;32m-> 1919\u001b[0m             decode_nested_example(\u001b[39mself\u001b[39;49m[column_name], value, token_per_repo_id\u001b[39m=\u001b[39;49mtoken_per_repo_id)\n\u001b[0;32m   1920\u001b[0m             \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m             \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m column\n\u001b[0;32m   1923\u001b[0m         ]\n\u001b[0;32m   1924\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   1925\u001b[0m         \u001b[39melse\u001b[39;00m column\n\u001b[0;32m   1926\u001b[0m     )\n\u001b[0;32m   1927\u001b[0m \u001b[39mreturn\u001b[39;00m decoded_batch\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\features\\features.py:1319\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[0;32m   1317\u001b[0m     \u001b[39m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m     \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m schema\u001b[39m.\u001b[39mdecode:\n\u001b[1;32m-> 1319\u001b[0m         \u001b[39mreturn\u001b[39;00m schema\u001b[39m.\u001b[39;49mdecode_example(obj, token_per_repo_id\u001b[39m=\u001b[39;49mtoken_per_repo_id)\n\u001b[0;32m   1320\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\features\\image.py:178\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     image \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 178\u001b[0m image\u001b[39m.\u001b[39;49mload()  \u001b[39m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\Christina\\anaconda3\\envs\\clipexplorer\\lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # subset of mscoco val dataset\n",
    "# dataset_mscoco_val = ce_data.MSCOCO_Val_Dataset(path='/Users/christina/Data/mscoco/validation/', batch_size=100) # TODO: update to a relative path\n",
    "# mscoco_val_images, mscoco_val_prompts, mscoco_val_dataset_name = get_data_helper(dataset_mscoco_val, filters=[], method=any)\n",
    "# export_data(mscoco_val_dataset_name, mscoco_val_images, mscoco_val_prompts)\n",
    "\n",
    "# subset of diffusionDB data\n",
    "dataset_diffusiondb = ce_data.DiffusionDB_Dataset(path=\"2m_first_1k\", batch_size=100)\n",
    "diffusiondb_images, diffusiondb_prompts, diffusiondb_dataset_name = get_data_helper(dataset_diffusiondb)\n",
    "# export_data(diffusiondb_dataset_name, diffusiondb_images, diffusiondb_prompts)\n",
    "\n",
    "# # Analyse filtered subset\n",
    "# dataset_mscoco_val = ce_data.MSCOCO_Val_Dataset(path='/Users/christina/Data/mscoco/validation/', batch_size=100) # TODO: update to a relative path\n",
    "# mscoco_val_images_dogs, mscoco_val_prompts_dogs, mscoco_val_dataset_dogs_name = get_data_helper(dataset_mscoco_val, filters=['dog'], method=any) \n",
    "# export_data(mscoco_val_dataset_dogs_name, mscoco_val_images_dogs, mscoco_val_prompts_dogs)\n",
    "\n",
    "example_image_dir = create_dir_if_not_exists(export_directory + 'example_images/')\n",
    "for img_id in range(10):\n",
    "    # thumb = diffusiondb_images[img_id].copy()\n",
    "    # thumb.thumbnail((100,100))\n",
    "    # thumb.save(example_image_dir+str(img_id)+'.jpg')\n",
    "    \n",
    "    # # Analyse rotated image\n",
    "    # dataset_rotated = ce_data.Rotate_Dataset(diffusiondb_images[img_id], diffusiondb_prompts[img_id], id=img_id)\n",
    "    # rotated_images, rotated_prompts, rotated_dataset_name = get_data_helper(dataset_rotated)\n",
    "    # export_data(rotated_dataset_name, rotated_images, rotated_prompts)\n",
    "\n",
    "    # # Analyze noisy image\n",
    "    # dataset_noise = ce_data.Noise_Dataset(diffusiondb_images[img_id], diffusiondb_prompts[img_id], id=img_id)\n",
    "    # noise_images, noise_prompts, noise_dataset_name = get_data_helper(dataset_noise)\n",
    "    # export_data(noise_dataset_name, noise_images, noise_prompts)\n",
    "    \n",
    "    # # Analyze blurry image\n",
    "    # dataset_blurry = ce_data.Blur_Dataset(diffusiondb_images[img_id], diffusiondb_prompts[img_id], id=img_id)\n",
    "    # blurry_images, blurry_prompts, blurry_dataset_name = get_data_helper(dataset_blurry)\n",
    "    # export_data(blurry_dataset_name, blurry_images, blurry_prompts)\n",
    "    \n",
    "    # # Analyze horizontally shifted image\n",
    "    # dataset_hshift = ce_data.HShift_Dataset(diffusiondb_images[img_id], diffusiondb_prompts[img_id], id=img_id)\n",
    "    # hshift_images, hshift_prompts, hshift_dataset_name = get_data_helper(dataset_hshift)\n",
    "    # export_data(hshift_dataset_name, hshift_images, hshift_prompts)\n",
    "    \n",
    "    # Analyze vertically shifted image\n",
    "    dataset_vshift = ce_data.VShift_Dataset(diffusiondb_images[img_id], diffusiondb_prompts[img_id], id=img_id)\n",
    "    vshift_images, vshift_prompts, vshift_dataset_name = get_data_helper(dataset_vshift)\n",
    "    export_data(vshift_dataset_name, vshift_images, vshift_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# pytorch show if gpu is available\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MSCOCO-Val_size-5000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full set of mscoco validation data (5000 samples)\n",
    "dataset_mscoco_val_large = ce_data.MSCOCO_Val_Dataset(path='/Users/christina/Data/mscoco/validation/', batch_size=None) # TODO: update to a relative path\n",
    "mscoco_val_images_large, mscoco_val_prompts_large, mscoco_val_dataset_large_name = get_data_helper(dataset_mscoco_val_large, filters=[], method=any)\n",
    "mscoco_val_dataset_large_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure\n",
    "export_directory = './exported_data_checkpoints/'\n",
    "\n",
    "dataset_directory = create_dir_if_not_exists(export_directory + mscoco_val_dataset_large_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found cached embeddings for MSCOCO-Val_size-5000_CLIP_RN50\n",
      "found cached embeddings for MSCOCO-Val_size-5000_CyCLIP_RN50\n"
     ]
    }
   ],
   "source": [
    "# export loss landscape of 5000 sample dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "\n",
    "\n",
    "for clip_model in ['CLIP', 'CyCLIP']:\n",
    "\n",
    "    image_embedding, text_embedding, logit_scale = ce_utils.get_embedding(clip_model, mscoco_val_dataset_large_name, mscoco_val_images_large, mscoco_val_prompts_large)\n",
    "\n",
    "    # loss difference\n",
    "    modality_distance = ce_utils.get_modality_distance(image_embedding, text_embedding)\n",
    "    loss = ce_utils.calculate_val_loss(image_embedding, text_embedding, logit_scale.exp())\n",
    "\n",
    "    image_embedding_closed, text_embedding_closed = ce_utils.get_closed_modality_gap(image_embedding, text_embedding)\n",
    "    modified_modality_distance = ce_utils.get_modality_distance(image_embedding_closed, text_embedding_closed)\n",
    "    modified_loss = ce_utils.calculate_val_loss(image_embedding_closed, text_embedding_closed, logit_scale.exp())\n",
    "\n",
    "    loss_landscape = {'original_distance': modality_distance, 'original_loss': loss, 'closed_distance': modified_modality_distance, 'closed_loss': modified_loss, 'loss_difference': modified_loss-loss}\n",
    "    \n",
    "    # compute loss landscape\n",
    "    modality_gap = ce_utils.get_modality_gap_normed(image_embedding, text_embedding)\n",
    "    \n",
    "    distance_lst = []\n",
    "    loss_lst = []\n",
    "    for delta in np.arange(-5.0, 5.0, 0.25): \n",
    "        modified_text_features = ce_utils.l2_norm(text_embedding) + 0.5 * delta * modality_gap\n",
    "        modified_text_features = ce_utils.l2_norm(modified_text_features)\n",
    "\n",
    "        modified_image_features = ce_utils.l2_norm(image_embedding) - 0.5 * delta * modality_gap\n",
    "        modified_image_features = ce_utils.l2_norm(modified_image_features)\n",
    "\n",
    "        avg_val_loss = ce_utils.calculate_val_loss(modified_image_features, modified_text_features, logit_scale = logit_scale.exp())\n",
    "\n",
    "        pca = PCA(n_components=6)\n",
    "        pca.fit(np.concatenate((image_embedding, text_embedding), axis=0))\n",
    "\n",
    "        gap_direction = ce_utils.get_gap_direction(modified_image_features, modified_text_features, pca)\n",
    "\n",
    "        loss_lst.append(avg_val_loss)\n",
    "\n",
    "        # Euclidean distance between mass centers\n",
    "        distance_lst.append(\n",
    "            ce_utils.get_modality_distance(modified_image_features, modified_text_features) * gap_direction\n",
    "        )\n",
    "\n",
    "    loss_landscape['distances'] = distance_lst\n",
    "    loss_landscape['losses'] = loss_lst\n",
    "\n",
    "    with open(\"%s/%s_loss_landscape.json\"%(dataset_directory, clip_model), \"w\") as file:\n",
    "        json.dump(loss_landscape, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
